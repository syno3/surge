# -*- coding: utf-8 -*-
"""DriverDrowsinessDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ykGcTyuFZHwNceMCitFC8fEpf1pPN7zH
"""
##### we build driver drowsiness detection algorithims
## train model using supervised CNN
## evaluate the model
## test model on sample dataset
## add SRGAN on low res images
### expected to be complete on thursday (10/7/21)

### we import the required modules
try:
  import cv2 as cv ## allow for computer vision
  import numpy as np ## convert data types and work with arrays
  import matplotlib.pyplot as plt ## plot images and training accuracy
  import logging ## create error messages
  import PIL ## loading some images
  import tensorflow as tf ## loading the main module
  from tensorflow import keras ## for the models
  from tensorflow.keras import layers ## create the CNN layers
  from tensorflow.keras.models import Sequential ## create the layers
  import os ##load the dataset
  from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPooling2D, Dropout
  from tensorflow.keras.models import Model
  from keras.preprocessing.image import ImageDataGenerator
except Exception as e:
  logging.critical('{}'.format(e))

### we initialize some variables
## kaggle datase('https://www.kaggle.com/dheerajperumandla/drowsiness-dataset')
## API (kaggle datasets download -d dheerajperumandla/drowsiness-dataset)

data = '/content/drowsiness-dataset/train'
cascade = '/content/har_face.xml'
eye_cascade = '/content/face.xml'

### we print the labels for the dataset
labels = os.listdir(data)

### we determine the total number of images in the dataset
import pathlib
data_dir = pathlib.Path(data)

image_count = len(list(data_dir.glob('*/*.jpg')))

### WE INITIALIZE SOME VARIABLES FOR THE DATASET
BATCH_SIZE = 32
IMG_HEIGHT = 180
IMG_WIDTH = 180

a = plt.imread('/content/drowsiness-dataset/train/yawn/340.jpg')
### we remove background from the images
def remove_Background(dir):
  ''' 
  :parameter: dir, where the files are located

  1.Read all image
  2.threshold on white ,Define lower and uppper limits
  3.Create mask to only select black
  4.apply morphology
  5.invert morp image
  6.apply mask to image

  :return: img

  '''
  for filename in data_dir.glob('*/*.jpg'):
    img = cv.imread(filename)
    pass

#### we take only the face in the directories
def face_for_yawn(direc, face_cas_path):
  ''' 
  we start by initialzing an empty lis
  variable IMG_SIZE
  List with categories needed
   
  we iterrate over the categories list
  creat a path link by joining dir and the category name
  create varibale with index of current directory

  iterate over the images in the directory link
  read the image as color version
  read the haar cascade
  detect the face with the haarcascade

  draw the ROI color green 
  resize the image
  append to the empty list, resized image and category

  return : list

  :parameter: direc, directory of the images
  :parameter: face_cas_path, directory of the haarcascade

  
  '''
  yaw_no = []
  IMG_SIZE = 145
  categories = ["yawn", "no_yawn"]
  for category in categories:
      path_link = os.path.join(direc, category)
      class_num1 = categories.index(category)
      print(class_num1)
      for image in os.listdir(path_link):
          image_array = cv.imread(os.path.join(path_link, image), cv.IMREAD_COLOR)
          face_cascade = cv.CascadeClassifier('/content/har_face.xml')
          faces = face_cascade.detectMultiScale(image_array, 1.3, 5)
          for (x, y, w, h) in faces:
              img = cv.rectangle(image_array, (x, y), (x+w, y+h), (0, 255, 0), 2)
              roi_color = img[y:y+h, x:x+w]
              resized_array = cv.resize(roi_color, (IMG_SIZE, IMG_SIZE))
              yaw_no.append([resized_array, class_num1])
  return yaw_no


yawn_no_yawn = face_for_yawn(data, cascade)

def get_data(direc, face_cas_path, eye_cas):
  ''' 
  create a list of the directories
  initialize the IMG_SIZE variable
  create an empy data list

  iterate over the labels
  join the labels with 
  return the index of the working dir

  resize the images
  append the resized images to the list

  :parameters: direc, directories of file
  :parameters: face_cas_path, path of the face cascade file
  :parameters: eye_cas, path of the eye cascade file
  :return : the list, data
  '''

  labels = ['Closed', 'Open']
  IMG_SIZE = 145
  closed = []
  for label in labels:
      path = os.path.join(direc, label)
      class_num = labels.index(label)
      class_num +=2
      print(class_num)
      for img in os.listdir(path):
          try:
              img_array = cv.imread(os.path.join(path, img), cv.IMREAD_COLOR)
              resized_array = cv.resize(img_array, (IMG_SIZE, IMG_SIZE))
              closed.append([resized_array, class_num])
          except Exception as e:
              print(e)

  return closed

data_train = get_data(data, cascade, eye_cascade)

def append_data():
#     total_data = []
    yaw_no = yawn_no_yawn
    data = data_train
    yaw_no.extend(data)
    return np.array(yaw_no)

new_data = append_data()

X = []
y = []
for feature, label in new_data:
    X.append(feature)
    y.append(label)

X = np.array(X)
X = X.reshape(-1, 145, 145, 3)

from sklearn.preprocessing import LabelBinarizer
label_bin = LabelBinarizer()
y = label_bin.fit_transform(y)

from sklearn.model_selection import train_test_split
seed = 42
test_size = 0.30
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, test_size=test_size)

'''  Data augemntation

rescale image
zoom to 0.2
flip the image
rotate the image 
'''

train_generator = ImageDataGenerator(rescale=1/255, zoom_range=0.2, horizontal_flip=True, rotation_range=30)
test_generator = ImageDataGenerator(rescale=1/255)

train_generator = train_generator.flow(np.array(X_train), y_train, shuffle=False)
test_generator = test_generator.flow(np.array(X_test), y_test, shuffle=False)
#input_shape=X_train.shape[1:])

model = Sequential()

model.add(Conv2D(256, (3, 3), activation="relu", input_shape=X_train.shape[1:]))
model.add(MaxPooling2D(2, 2))

model.add(Conv2D(128, (3, 3), activation="relu"))
model.add(MaxPooling2D(2, 2))

model.add(Conv2D(64, (3, 3), activation="relu"))
model.add(MaxPooling2D(2, 2))

model.add(Conv2D(32, (3, 3), activation="relu"))
model.add(MaxPooling2D(2, 2))

model.add(Flatten())
model.add(Dropout(0.5))

model.add(Dense(64, activation="relu"))
model.add(Dense(4, activation="softmax"))

model.compile(loss="categorical_crossentropy", metrics=["accuracy"], optimizer="adam")

model.compile(loss="categorical_crossentropy", metrics=["accuracy"], optimizer="adam")

model.summary()

history = model.fit(train_generator, epochs=10, validation_data=test_generator, shuffle=True, validation_steps=len(test_generator))

#model.save("drowiness_new.h5")
#model.save("drowiness_new6.model")

